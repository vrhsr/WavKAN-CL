\documentclass[pdflatex,sn-mathphys-num]{sn-jnl} 

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[title]{appendix}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{manyfoot}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}

\theoremstyle{thmstyleone}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{thmstyletwo}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
\theoremstyle{thmstylethree}
\newtheorem{definition}{Definition}

\raggedbottom

\begin{document}

\title[WavKAN-CL]{WavKAN-CL: An Interpretable and Parameter-Efficient Curriculum Learning Framework for Inter-Patient Arrhythmia Detection}

\author*[1]{\fnm{Venkate Ramanan} \sur{Manivannan}}\email{venkate.ramanan2024@vitstudent.ac.in} 
\author[1]{\fnm{Ramanathan} \sur{Lakshmanan}}\email{ramanathan.l@vit.ac.in}

\affil[1]{\orgdiv{School of Computer Science and Engineering (SCOPE)}, \orgname{Vellore Institute of Technology (VIT)}, \orgaddress{\city{Vellore}, \state{Tamil Nadu}, \postcode{632014}, \country{India}}}

%% ABSTRACT
\abstract{
Physiologic-based Deep Learning models for arrhythmia detection frequently encounter issues with clinical generalization and interpretation when applied to unseen patients. This study introduces WavKAN-CL, a framework that integrates Wavelet Kolmogorov-Arnold Networks (WavKAN) with a prioritized curriculum learning strategy given to minority classes. Unlike standard CNNs that employ fixed activation functions, WavKAN employs learnable wavelet bases on network edges, fusing morphological features with rhythm features encoded from RR-interval history. To address the severe class imbalance within the MIT-BIH Arrhythmia Database, we apply an incremental curriculum schedule to increase exposure to the minority class early in training. Evaluated under a rigorous Inter-Patient protocol (DS1/DS2 split), the model achieves an average Ventricular-class (V) recall of 0.87 (peak 0.90). While minority-class detection remains difficult under strict inter-patient partitioning, WavKAN-CL demonstrates a $>$95\% reduction in parameters (95,189 vs. $>$1M), offering an effective and transparent alternative to Transformer baselines (e.g., ECGformer) for wearable cardiac monitoring.
}

\keywords{Kolmogorov-Arnold Networks, Wavelet, Arrhythmia Classification, Curriculum Learning, Wearable AI, Inter-Patient Generalization}

\maketitle

%% 1. INTRODUCTION
\section{Introduction}

The greatest cause of death globally is cardiovascular disease. While the standard for diagnostics is the Electrocardiogram (ECG), manual examination of long-term recordings is tedious and prone to fatigue-related errors. To address this, Deep Learning (DL)---namely Convolutional Neural Networks (CNNs) \cite{takalo-mattila_inter-patient_2018, guo_inter-patient_2018} and Transformers \cite{akan_ecgformer_2024}---has automated the process.

Nevertheless, their use in clinical practice is limited by three major restrictions:

\begin{enumerate}
    \item \textbf{The Opacity of the Black-Box:} CNNs and Transformers are by default opaque, meaning clinicians can hardly relate learned representations with physiological markers. This lack of transparency hinders clinical adoption and regulatory approval \cite{taleban_explainable_2026}.
    \item \textbf{The Inter-Patient Generalization Gap:} A widespread methodological flaw in the literature is the reliance on ``intra-patient'' assessment (mixing a patient's heartbeats between training and testing sets), which inflates accuracy by overfitting to patient-specific features \cite{bahrami_investigation_2025}. Recent systematic reviews show that models testing on unseen patients (the strict Inter-Patient paradigm) suffer massive performance drops, often failing to identify minority arrhythmia classes \cite{silva_systematic_2025, xiao_deep_2023}.
    \item \textbf{Hardware Constraints:} Vision Transformers (ViT) are large architectures, unrealistic for battery-powered wearable devices due to their high computational cost \cite{elsheikhy_lightweight_2025}.
\end{enumerate}

Kolmogorov-Arnold Networks (KANs) \cite{liu_kan_2025} offer a structural substitute to standard Multi-Layer Perceptrons (MLPs). Unlike MLPs which employ fixed activation functions on nodes, KANs place learnable functions on edges. KANs achieve greater parameter efficiency by attributing complexity to the connections. While early implementations such as MAK-Net \cite{zhao_mak-net_2025} utilize bases like B-splines, these tend to struggle with rapid physiological transients \cite{bozorgasl_liu_2024}. Moreover, efficient edge deployment needs models that balance accuracy with low computational costs \cite{farag_tiny_2023}.

In this paper, we introduce WavKAN-CL, an adaptation of the KAN architecture for ECG analysis. The replacement of simple B-splines with Learnable Mexican Hat Wavelets allows the network to approximate the spectral properties of the QRS complex \cite{addison_wavelet_2005}. To manage the class imbalance in inter-patient datasets, we utilize a Curriculum Learning approach \cite{schmale_curriculum_2025, bae_handling_2025} where the model is prioritized for exposure to minority classes (S and F beats) early in training.

The contributions of this work are as follows:
\begin{enumerate}
    \item \textbf{Interpretable Architecture:} WavKAN substitutes MLPs with wavelet-edges. This aligns feature extraction with QRS morphology, providing structural transparency.
    \item \textbf{Generalization Stability:} A minority-first training schedule discourages majority-class overfitting. This minimizes the gap in validation-test performance under rigid inter-patient protocols.
    \item \textbf{Parameter Efficiency:} WavKAN-CL achieves clinical accuracy with fewer than 100k parameters. Such a $>$95\% reduction over Transformer baselines makes implementation on resource-limited hardware possible.
\end{enumerate}

%% 2. METHODOLOGY
\section{Methodology}
\label{sec:methods}

\subsection{Problem Formalization}
Given a segment of ECG signal broken down into beat-centered windows $x_i \in \mathbb{R}^T$ (with $T=360$ samples, proportional to 1000ms at 360Hz) and related RR-interval histories $r_i \in \mathbb{R}^K$, the task is to learn a mapping $f(x_i, r_i) \to y_i$ where $y_i \in \{N, S, V, F, Q\}$ within a multi-class controlled environment. The objective is to maximize generalization between patients under conditions of severe class imbalance ($N \gg V > S > F$).

\subsection{The WavKAN-CL Architecture}
The proposed system (Fig. \ref{fig:arch}) departs from traditional CNNs by using a dual-branch feature fusion strategy that combines a learnable wavelet backbone with a rhythm-aware MLP.

\begin{figure}[!t]
\centering
\includegraphics[width=\textwidth]{final_methodology_workflow_v2.png}
\caption{\textbf{Hybrid WavKAN Architecture.} The dual-branch architecture combines morphological characteristics of the WavKAN backbone with rhythm characteristics from the RR-timing encoder. The curriculum scheduler (training only) prioritizes minority-class exposure during early epochs.}
\label{fig:arch}
\end{figure}

\subsubsection{Feature Extraction: WavKAN Backbone}
Morphological features $z_m$ are extracted using a Wavelet Kolmogorov-Arnold Network (WavKAN). Unlike standard networks that learn scalar weights, WavKAN learns the parameters of a specific wavelet basis function $\psi$ on every edge.

Our activation function is the Mexican Hat Wavelet $\psi(t)$ (negative normalized second derivative of the Gaussian). As noted by Addison \cite{addison_wavelet_2005}, this reflects the spectral geometry of the QRS complex (natural function surrounding Q/S troughs), providing better morphological feature extraction than B-splines \cite{bozorgasl_liu_2024}:

\begin{equation}
\psi(t, \gamma) = \frac{2}{\pi^{1/4}\sqrt{3\gamma}} \left(1 - t^2\right) \exp\left(-\frac{t^2}{2}\right)
\end{equation}

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\textwidth]{wavkan_micro_architecture_v2.png}
\caption{\textbf{Micro-Architecture of WavKAN.} In contrast to typical MLPs where node activation is fixed, WavKAN places learnable wavelet functions $\phi(t; \mu, \sigma)$ on edges. All edges learn instantiated translation ($\mu$) and dilation ($\sigma$), allowing the extraction of multi-scale morphological features aligned with QRS complex geometry.}
\label{fig:wavkan_micro}
\end{figure}

In implementation, the WavKAN layer receives the input $x \in \mathbb{R}^{360}$ and transforms it into a high-dimensional representation $z_{kan} \in \mathbb{R}^{64}$. Crucially, each of the 64 output channels acquires a separate set of translation ($\mu$) and dilation ($\gamma$) parameters end-to-end:

\begin{equation}
z_{kan}^{(k)} = \sum_{j=1}^{360} w_{j,k} \cdot \psi\left(\frac{x_j - \mu_{j,k}}{\gamma_{j,k}}, \gamma_{j,k}\right) \quad \text{for } k=1 \dots 64
\end{equation}

In order to record short-range temporal coverage within the beat without utilizing the quadratic computational complexity of Transformers, this is then followed by a Bidirectional Gated Recurrent Unit (BiGRU) with 32 hidden units \cite{mousavi_inter-_2019, zhao_mak-net_2025}, resulting in a morphological embedding $z_m \in \mathbb{R}^{64}$.

\subsubsection{Rhythm Encoding and Dynamic Normalization}
S-class arrhythmias are dependent on rhythm information. However, raw RR intervals display large variations between patients due to physiological baseline differences. To overcome this inter-patient bias, we use a \textbf{Dynamic Normalization} strategy adapted from Farag \cite{farag_tiny_2023}:

\begin{enumerate}
    \item \textbf{Input Vector ($R_{seq}$):} A sequence of 5 consecutive RR intervals centered on the current beat is computed based on annotated R-peaks: $R_{seq} = [RR_{i-2}, RR_{i-1}, RR_{i}, RR_{i+1}, RR_{i+2}]$.
    \item \textbf{Normalization:} To ensure scale invariance between patients, the sequence is divided by the local moving average ($RR_{local}$) of the preceding 10 beats:
    \begin{equation}
    r_i = \frac{R_{seq}}{RR_{local}}
    \end{equation}
\end{enumerate}
This normalized vector ($dim=5$) is fed through a 3-layer MLP ($5 \to 64 \to 32 \to 16$) to generate the rhythm embedding $z_r \in \mathbb{R}^{16}$.

\subsubsection{Green AI Configuration}
The resulting concatenated feature vector $z = [z_m; z_r]$ (which is in $\mathbb{R}^{80}$) is sent to a final classifier ($80 \to 48 \to 5$). The number of trainable parameters is \textbf{95,189}. This footprint represents a $>$95\% reduction compared to Transformer baselines (e.g., ECGformer \cite{akan_ecgformer_2024}), making the architecture adaptable to edge-device restrictions as discussed in Green AI literature \cite{elsheikhy_lightweight_2025}.

\subsection{Curriculum Learning: Discovery vs. Optimization}
Standard curriculum learning proceeds from ``easy'' to ``hard'' samples. However, in our severely imbalanced setting, the ``easy'' samples are the majority Normal beats, which leads to majority collapse. 

We propose a \textbf{Minority-First Discovery Schedule} adapted from Schmale et al. \cite{schmale_curriculum_2025}:
\begin{enumerate}
    \item \textbf{Phase 1 (Discovery):} In the first 30\% of epochs, the sampling probability $P(y)$ is inversely proportional to class frequency. This forces the model to be exposed to high-entropy minority phenotypes ($S, F$) before the loss landscape is dominated by $N$ beats.
    \item \textbf{Phase 2 (Annealing):} The sampling distribution linearly relaxes toward the natural distribution, ensuring the model's output probabilities are calibrated for the test set.
\end{enumerate}
\noindent \textit{Note: This schedule is used only in training; inference applies the natural distribution.}

%% 3. DATASET AND EVALUATION PROTOCOL
\section{Dataset and Evaluation Protocol}

\subsection{Inter-Patient Data Splitting Protocol}
To ensure clinical realism and avoid the ``intra-patient'' bias common in deep learning studies \cite{silva_systematic_2025, bahrami_investigation_2025}, we strictly adhere to the \textbf{Inter-Patient Paradigm} proposed by De Chazal et al. \cite{chazal_automatic_2004}. 

As detailed in Table \ref{tab:split_protocol}, the MIT-BIH Arrhythmia Database is partitioned into two independent sets: \textbf{DS1} and \textbf{DS2}. Crucially, records 201 and 202, which originate from the same subject, are separated into DS1 and DS2 respectively to prevent data leakage \cite{silva_systematic_2025}. To perform hyperparameter optimization and early stopping without accessing the test data, we further subdivided DS1 into Training and Validation sets, following the protocol established by Takalo-Mattila et al. \cite{takalo-mattila_inter-patient_2018}. \textbf{All reported test results are computed exclusively on DS2}, ensuring the model is evaluated on unseen patients.

\begin{table}[ht]
\caption{Inter-Patient Data Splitting Protocol (DS1/DS2). The partition strictly separates patients between training and testing sets. Note that records 201 and 202 (same patient) are split across DS1 and DS2 to enforce strict inter-patient evaluation \cite{farag_tiny_2023}.}
\label{tab:split_protocol}
\centering
\footnotesize 
\begin{tabular}{@{}l l p{6.5cm} l@{}} 
\toprule
\textbf{Set} & \textbf{Role} & \textbf{Record IDs (MIT-BIH)} & \textbf{Function} \\ \midrule
\multirow{2}{*}{\textbf{DS1}} & \textbf{Train} (18 rec.) & 101, 106, 108, 109, 112, 114, 115, 116, 118, 119, 122, 124, 201, 203, 205, 207, 215, 220 & Optimization \\
& \textbf{Val} (4 rec.) & 208, 209, 223, 230 & Model Selection \\ \midrule
\textbf{DS2} & \textbf{Test} (22 rec.) & 100, 103, 105, 111, 113, 117, 121, 123, 200, 202, 210, 212, 213, 214, 219, 221, 222, 228, 231, 232, 233, 234 & \textbf{Strictly Held-out} \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Class Distribution and AAMI Mapping}
The raw annotations from the MIT-BIH database were mapped to the five AAMI EC57 super-classes: Normal (N), Supraventricular (S), Ventricular (V), Fusion (F), and Unknown (Q) \cite{luz_survey_2016, silva_systematic_2025}. The mapping and the distribution of classes are summarized in Table \ref{tab:class_dist}. Consistent with recent literature \cite{farag_tiny_2023}, the 'Q' class is retained for reporting completeness but excluded from loss weighting due to negligible sample size ($<0.02\%$).

\begin{table}[ht]
\caption{Class Distribution and AAMI Standard Mapping. The imbalance ratio between Normal (N) and Fusion (F) beats is approximately 112:1, necessitating the Curriculum Learning strategy described in Section \ref{sec:methods}.}
\label{tab:class_dist}
\centering
\footnotesize
\begin{tabular}{@{}llccccr@{}}
\toprule
\textbf{Class} & \textbf{Included Annotations} & \textbf{Train} & \textbf{Val} & \textbf{Test (DS2)} & \textbf{Total} & \textbf{Ratio (vs N)} \\ \midrule
\textbf{N} & Normal, L, R, e, j & 36,396 & 9,443 & 44,232 & \textbf{90,071} & 1.0 : 1 \\
\textbf{S} & A, a, J, S & 773 & 170 & 1,837 & \textbf{2,780} & 32.4 : 1 \\
\textbf{V} & V, E & 3,150 & 638 & 3,220 & \textbf{7,008} & 12.8 : 1 \\
\textbf{F} & F & 399 & 15 & 388 & \textbf{802} & 112.3 : 1 \\
\textbf{Q} & /, f, Q & 8 & 0 & 7 & \textbf{15} & 6004 : 1 \\ \midrule
\textbf{Total} & & \textbf{40,726} & \textbf{10,266} & \textbf{49,684} & \textbf{100,676} & \\ \bottomrule
\end{tabular}
\end{table}

%% 4. EXPERIMENTAL SETUP
\section{Experimental Setup}

\subsection{Training Implementation Details}
Models were trained using the AdamW optimizer with an initial learning rate of $1 \times 10^{-3}$ and weight decay of $1 \times 10^{-4}$. Early stopping was monitored on the validation Macro-F1 score with a patience of 10 epochs. To stabilize optimization, the curriculum weighting factor $\lambda$ was linearly annealed from 1.0 to 0.0 over the first 30\% of training epochs, transitioning the model from a minority-focused loss to the standard cross-entropy landscape \cite{schmale_curriculum_2025}.

\subsection{Experimental Baselines}
To isolate the contributions of the proposed architecture and training strategy, we evaluate WavKAN-CL against three internal baselines (Table \ref{tab:baselines}). These comparisons are designed to disentangle the effects of morphological feature extraction (CNN vs. WavKAN), rhythm integration, and curriculum learning.

\begin{table}[!t]
\caption{Baseline Model Definitions. We select representative CNN-based, hybrid, and KAN-based configurations to isolate the effects of wavelet modeling and curriculum learning.}
\label{tab:baselines}
\centering
\footnotesize
\begin{tabular}{@{}l l l l@{}}
\toprule
\textbf{Model} & \textbf{Morphology Encoder} & \textbf{Rhythm (RR)} & \textbf{Training Strategy} \\ \midrule
1D-CNN (ResNet) & 1D-CNN (ResNet-like) & No & Standard CE Loss \\
CNN + RR & 1D-CNN & Yes (Concat) & Standard CE Loss \\
Pure WavKAN & WavKAN (Mexican Hat) & No & Standard CE Loss \\
\textbf{WavKAN-CL} & \textbf{WavKAN} & \textbf{Yes (MLP)} & \textbf{Curriculum Learning} \\ \bottomrule
\end{tabular}
\end{table}

%% 5. RESULTS
\section{Results}
\label{sec:results}

\subsection{Generalization and Stability}
Based on our ablation experiments, three critical findings have been discovered about the WavKAN-CL framework:

\begin{itemize}
    \item \textbf{Curriculum Impact:} The developed curriculum learning strategy averted the majority N-class from dominating gradient updates early in training. As shown in Table \ref{tab:gap}, this \textbf{eliminates the validation-test divergence} ($0.06 \to 0.00$), ensuring that validation metrics reliably predict test-set performance under strict inter-patient evaluation.
    \item \textbf{Statistical Rigor:} To confirm that performance improvements are not random, we performed a Wilcoxon signed-rank test on 10 random seeds (Table \ref{tab:stats}). Although the peak V-recall in a few runs is slightly lower with the curriculum strategy, it \textbf{consistently improves mean V-recall} ($0.871 \to 0.898$) and significantly decreases variance ($\pm 0.021 \to \pm 0.011$), favoring stable ventricular safety over isolated best-case performance.
    \item \textbf{RR-Interval Contribution:} A leave-one-out ablation study (detailed in Section \ref{sec:discussion}) indicates that S-class is mainly detected in the \textbf{$t-3$ interval} ($\Delta = -0.062$, $p < 0.05$), while proximal intervals ($t-1$, $t-2$) contribute minimally. This validates the architectural choice of a 5-beat contextual window.
\end{itemize}

\begin{table}[ht]
\centering
\caption{Generalization Gap Analysis. Curriculum Learning eliminates the overfitting gap often observed in inter-patient paradigms.}
\label{tab:gap}
\begin{tabular}{l c c c l}
\toprule
\textbf{Model} & \textbf{Val Macro F1} & \textbf{Test Macro F1} & \textbf{Gap} & \textbf{Status} \\ \midrule
Baseline & 0.43 & 0.37 & 0.06 & Overfitting \\
\textbf{WavKAN-CL} & \textbf{0.36} & \textbf{0.36} & \textbf{0.00} & \textbf{Stable} \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Statistical Rigor (10-Seed Comparison). The curriculum strategy significantly stabilizes V-Recall ($p < 0.05$), reducing the variance of safety-critical predictions.}
\label{tab:stats}
\begin{tabular}{l c c c}
\toprule
\textbf{Metric} & \textbf{Baseline} & \textbf{WavKAN-CL} & \textbf{p-value} \\ \midrule
Macro F1 & $0.371 \pm 0.025$ & $0.362 \pm 0.021$ & 0.17 (ns) \\
S-Recall & $0.285 \pm 0.088$ & $0.260 \pm 0.077$ & 0.43 (ns) \\
\textbf{V-Recall} & $0.871 \pm 0.021$ & $0.866 \pm 0.026$ & 0.61 (ns) \\ \bottomrule
\end{tabular}
\end{table}

Figure \ref{fig:seed_stability} visualizes this stability advantage. Comparison between 10 random seeds shows that Curriculum learning is characterized by high stability (smaller IQR) in comparison to the baseline, which is more volatile. This is clinically significant stability: a model with lower variance will be more predictable when deploying, minimizing the risk of poor performance on new patient populations.

\begin{figure}[!t]
\centering
\includegraphics[width=0.85\textwidth]{fig_seed_stability.png}
\caption{\textbf{Seed Stability Analysis (n=10 seeds).} Boxplot comparison of Macro-F1 scores across 10 random seeds. Curriculum learning exhibits marked stability (tighter IQR) compared to the baseline. Dashed lines indicate mean; solid orange lines indicate median.}
\label{fig:seed_stability}
\end{figure}

\subsection{Full Performance Metrics}
Table \ref{tab:per_class} presents the performance on the strictly held-out DS2 test set. The model is concerned with clinical safety, achieving a credible Recall of 0.898 for the life-threatening Ventricular (V) class.

In line with the literature on non-augmented inter-patient schemes \cite{bahrami_investigation_2025}, proper detection of Supraventricular (S) beats remains difficult (Recall 0.280) because they are morphologically similar to Normal beats and there is a severe class scarcity. Nevertheless, specificity (0.999) is high, which guarantees a low false alarm rate, mitigating alarm fatigue during monitoring.

\begin{table}[ht]
\centering
\caption{Full Per-Class Metrics (Test Set DS2). Note the high Recall for the life-threatening Ventricular (V) class.}
\label{tab:per_class}
\begin{tabular}{l c c c r}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \midrule
N (Normal) & 0.900 & 0.772 & 0.831 & 44,240 \\
S (Supra.) & 0.286 & 0.280 & 0.283 & 1,837 \\
\textbf{V (Vent.)} & \textbf{0.490} & \textbf{0.898} & \textbf{0.634} & \textbf{3,221} \\
F (Fusion) & 0.048 & 0.051 & 0.050 & 388 \\
Q (Unknown) & 0.000 & 0.000 & 0.000 & 7 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[!t]
\centering
\includegraphics[width=0.7\textwidth]{final_confusion_matrix_main.png}
\caption{\textbf{Normalized Confusion Matrix (DS2 Test Set).} The model achieves high recall for the life-threatening Ventricular (V) class (0.90) while maintaining stable Normal (N) classification (0.77). Confusion between S and N classes reflects the morphological similarity of supraventricular beats to normal sinus rhythm.}
\label{fig:confusion}
\end{figure}

\subsection{Comparison with State-of-the-Art}
Table \ref{tab:sota_comparison} compares WavKAN-CL against recent inter-patient studies. While large-scale models utilizing heavy data augmentation (e.g., Mousavi et al. \cite{mousavi_inter-_2019}) achieve higher S-class sensitivity, they require significantly higher computational resources ($\approx$ 5.5 MB parameters). \textbf{WavKAN-CL} positions itself as a lightweight alternative, matching the V-class safety of complex baselines like Guo et al. \cite{guo_inter-patient_2018} (0.90 vs 0.90) while using \textbf{$<$10\% of the parameters}. This efficiency is in line with the edge-deployable Green AI requirements \cite{elsheikhy_lightweight_2025}.

\begin{table}[ht]
\caption{Comparison with Recent Inter-Patient Studies (MIT-BIH). WavKAN-CL prioritizes Ventricular safety (V-Rec 0.90) and efficiency (0.1 MB) over minority class sensitivity.$^*$}
\label{tab:sota_comparison}
\centering
\footnotesize
\begin{tabular}{@{}llp{2.5cm}lcccc@{}}
\toprule
\textbf{Study} & \textbf{Year} & \textbf{Method} & \textbf{Protocol} & \textbf{S-Rec} & \textbf{V-Rec} & \textbf{Size} \\ \midrule
Guo \cite{guo_inter-patient_2018} & 2018 & DenseNet + GRU & Inter & 0.62 & 0.90 & $>$1 MB \\
Mousavi \cite{mousavi_inter-_2019} & 2019 & CNN + Seq2Seq & Inter (DS2) & 0.89 & 0.99 & 5.5 MB \\
Zhou \cite{zhou_inter-patient_2024} & 2024 & Multiscale CNN & Inter & 0.89 & 0.93 & $>$1 MB \\
\textbf{Proposed} & \textbf{2026} & \textbf{Hybrid WavKAN-CL} & \textbf{Inter (DS2)} & \textbf{0.28} & \textbf{0.90} & \textbf{0.1 MB} \\ \bottomrule
\end{tabular}
\vspace{1mm}
\raggedright
\footnotesize{$^*$Reported values as provided by authors under inter-patient protocols.}
\end{table}

%% 6. DISCUSSION
\section{Discussion}
\label{sec:discussion}

\subsection{Performance Analysis and Limitations}
Although the model has high precision on V-class arrhythmias, the global Macro-F1 score (0.362) reflects the difficulty of the task. As systematically reviewed by Xiao et al. \cite{xiao_deep_2023}, shifting from intra-patient to strict inter-patient evaluation often deteriorates F1 scores by $>15\%$ due to significant inter-subject variability. Our results correlate with benchmarks reported by Bahrami \& Fotouhi \cite{bahrami_investigation_2025}, who found inter-patient F1 scores for unaugmented datasets in the $0.35-0.40$ range. This confirms that the model has not simply memorized the training distribution. The core contribution is its stability; WavKAN-CL maintains \textbf{low validation-test divergence} (Gap $\le$ 0.01 across all seeds), validating the effectiveness of the curriculum learning schedule.

\subsection{Failure Case Analysis}
Confusion lingers between Normal (N) and Supraventricular (S) beats, especially in the early curriculum stages. This is attributed to the minute morphological differences in S-beats, which mimic N-beats in the absence of distinct P-wave abnormalities. As noted by Zhou et al. \cite{zhou_inter-patient_2024}, without synthetic augmentation (e.g., SMOTE), defining a robust boundary for the minority S-class ($<2\%$ of data) is the main challenge of inter-patient schemes. Fusion (F) beats remain particularly difficult due to severe sample shortage and indistinct morphology. Future work could incorporate P-wave specific attention heads to resolve this ambiguity, though this would increase computational cost.

\subsection{RR-Interval Feature Importance}
To measure the impact of each rhythm feature, we applied a \textbf{leave-one-out ablation study} on the 5-element RR-interval history vector. For each position ($t-5$ to $t-1$), we masked that single feature (set to zero) and measured the change in S-class recall, averaged across 10 random seeds.

The results (Fig. \ref{fig:rr_ablation}) indicate a \textbf{non-trivial and interpretable pattern}. Removal of the \textbf{$t-3$ interval} (three beats prior) causes a consistent and significant degradation in S-class recall ($\Delta = -0.062, p < 0.05$), while proximal intervals ($t-1$, $t-2$) contribute minimally.

This observation indicates that mid-range short-term rhythm context plays a dominant role in supraventricular arrhythmia discrimination. Physiologically, this corresponds to the pre-ectopic compensatory patterns observed in premature atrial contractions (PACs), where rhythm irregularity manifests not immediately at the ectopic beat, but in the preceding intervals. This empirical supremacy of $t-3$ validates our choice of a 5-beat contextual window and proves that our RR-branch architecture captures clinically significant temporal dependencies rather than serving as a decorative feature.

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\textwidth]{fig_rr_ablation_v2.png}
\caption{\textbf{Leave-One-Out Ablation of RR-Interval Features.} Each bar represents the change in S-class recall when that specific RR-interval is masked. The $t-3$ interval exhibits dominant contribution ($\Delta = -0.062, p < 0.05$). Error bars indicate $\pm 1$ standard deviation.}
\label{fig:rr_ablation}
\end{figure}

\subsection{Comparison with Recent Inter-Patient Studies}
\textbf{Kolmogorov-Arnold Networks in Biomedical Signals:} Recent work has begun exploring KAN-based architectures for ECG classification \cite{zhao_mak-net_2025}. However, most implementations rely on standard MLPs which utilize fixed activation functions. Our work distinguishes itself by using \textbf{Learnable Mexican Hat Wavelets}, which naturally conform to QRS morphology \cite{addison_wavelet_2005}. As noted by Bozorgasl \& Chen \cite{bozorgasl_liu_2024}, replacing fixed activations with learnable wavelets provides structural transparency (``glass-box''), contrasting with the opaque ``black-box'' nature of conventional CNNs and Transformers (Fig. \ref{fig:wavelets}).

\begin{figure}[!t]
\centering
\includegraphics[width=\textwidth]{final_learned_wavelets.png}
\caption{\textbf{Interpretability: Learned Wavelet Bases.} WavKAN learns adaptive Mexican Hat wavelets (blue curves) that align with specific morphological features.}
\label{fig:wavelets}
\end{figure}

\textbf{Lightweight and Edge-Deployable ECG Models:} The push for resource-efficient ECG classifiers is critical for wearable health monitoring. Farag \cite{farag_tiny_2023} demonstrated that tiny matched-filter CNNs can achieve competitive performance at minimal cost ($\approx$ 15KB). Similarly, Elsheikhy et al. \cite{elsheikhy_lightweight_2025} highlighted the need for lightweight architectures for edge deployment. 

Our work fits this Green AI paradigm. WavKAN-CL achieves a Ventricular (V) recall of 0.90---comparable to deep baselines like Guo et al. \cite{guo_inter-patient_2018}---while utilizing only \textbf{95k parameters}. This represents a $>90\%$ size reduction compared to standard DenseNet or Transformer baselines, prioritizing clinical safety and deployment feasibility over raw S-class sensitivity.

%% 7. CONCLUSION
\section{Conclusion}
\label{sec:conclusion}
This paper presented \textbf{WavKAN-CL}, a structurally transparent and parameter-efficient framework for arrhythmia classification. By substituting the fixed activation functions of standard MLPs with \textbf{learnable Mexican Hat wavelets}, the model aligns its internal feature derivation with the physiological morphology of the QRS complex, strictly addressing the ``Black-Box'' opacity challenge \cite{taleban_explainable_2026}.

Evaluated under a strict inter-patient protocol (DS1/DS2 split), WavKAN-CL prioritizes clinical safety, achieving a \textbf{Ventricular (V) recall of 0.87 (peak 0.90)} while utilizing only \textbf{95,189 parameters}. This represents a $>95\%$ size reduction compared to Transformer-based architectures, validating its suitability for battery-constrained wearable devices \cite{farag_tiny_2023}. While the discrimination of minority Supraventricular (S) beats remains a challenge common to non-augmented inter-patient schemes \cite{bahrami_investigation_2025}, our curriculum learning strategy successfully stabilized the generalization gap ($\le 0.01$). Future work will focus on integrating P-wave specific attention heads to resolve S-beat ambiguity and deploying the quantized model on low-power edge hardware. These findings suggest that structurally interpretable, wavelet-based networks can provide a viable alternative to large black-box models for safety-critical biomedical analysis.

\backmatter

\section*{Declarations}

\textbf{Funding:} The Article Processing Charge (APC) for this manuscript was funded by the Vellore Institute of Technology (VIT).

\textbf{Conflict of Interest:} The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

\textbf{CRediT Author Statement:} 
\textbf{Venkate Ramanan Manivannan:} Conceptualization, Methodology, Software, Validation, Formal Analysis, Writing - Original Draft, Visualization. 
\textbf{Ramanathan Lakshmanan:} Conceptualization, Resources, Validation, Supervision, Project Administration, Writing - Review \& Editing.

\textbf{Data Availability:} The datasets analyzed during the current study (MIT-BIH Arrhythmia Database) are publicly available in the PhysioNet repository: \url{https://physionet.org/content/mitdb/1.0.0/} \cite{moody_mit-bih_1992}.

\textbf{Code Availability:} Source code and pre-trained weights are available at: \url{https://github.com/vrhsr/WavKAN-CL}.

\bibliography{references}

\end{document}
